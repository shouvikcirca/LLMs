{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmrWI1GlOdJwV1i1gv8bHX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shouvikcirca/LLMs/blob/main/HuggingFace_MachineTranslation_hi_to_en_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "metadata": {
        "id": "vRqcTAGRJ42g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install datasets"
      ],
      "metadata": {
        "id": "ur_9Bj7l2uRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translation pipeline\n",
        "from datasets import load_dataset\n",
        "\n",
        "iitbdataset = load_dataset(\"cfilt/iitb-english-hindi\")"
      ],
      "metadata": {
        "id": "ohJlNT8qNRAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(iitbdataset[\"train\"]),len(iitbdataset[\"validation\"]),len(iitbdataset[\"test\"])"
      ],
      "metadata": {
        "id": "s-A8fJdxNRC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "demodataset = DatasetDict({\"train\": iitbdataset['test'],\"validation\":iitbdataset['validation']})"
      ],
      "metadata": {
        "id": "MONQCi-is-yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokenizer_training_corpus():\n",
        "    global demodataset\n",
        "    for start_idx in range(0, len(demodataset['train']), 10):\n",
        "        samples = demodataset['train'][start_idx : start_idx + 10]['translation']\n",
        "        samples = [i['hi'] for i in samples]\n",
        "        yield(samples)"
      ],
      "metadata": {
        "id": "Upbde5kheSEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_training_corpus = get_tokenizer_training_corpus()"
      ],
      "metadata": {
        "id": "k3GaRZXMeSGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# next(training_corpus)"
      ],
      "metadata": {
        "id": "sEsK_nfjeSIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading model to be used\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "old_tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
      ],
      "metadata": {
        "id": "tw6ShGoQNRFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = old_tokenizer.train_new_from_iterator(tokenizer_training_corpus, 52000) # 52000 is the vocabulary length"
      ],
      "metadata": {
        "id": "_HxTmPGtjS7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example = 'आपका नाम क्या है'\n",
        "# tokens = tokenizer.tokenize(example)\n",
        "# tokens"
      ],
      "metadata": {
        "id": "fHVjeJv4jS9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 128\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [ex[\"hi\"] for ex in examples[\"translation\"]]\n",
        "    targets = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
        "    model_inputs = tokenizer(\n",
        "        inputs, text_target=targets, max_length=max_length, truncation=True, padding=True\n",
        "    )\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "wtnjaxc-jTAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model_checkpoint = \"t5-small\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "--xY5Tr2jTCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "BzqEA0NymqIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = demodataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns = iitbdataset[\"train\"].column_names,\n",
        ")"
      ],
      "metadata": {
        "id": "CofcUzVPqN8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch = data_collator([tokenized_datasets[\"validation\"][i] for i in range(1, 3)])\n",
        "# batch.keys()"
      ],
      "metadata": {
        "id": "nUAecP-0mXVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch['labels']"
      ],
      "metadata": {
        "id": "k0N_jTBXfYI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch[\"decoder_input_ids\"] # To see if they are the shifted versions of batch['labels']"
      ],
      "metadata": {
        "id": "_y2aDy2pfYKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip uninstall tensorflow -y\n",
        "! pip install tensorflow==2.14\n"
      ],
      "metadata": {
        "id": "bNVn4gxl_jmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install evaluate --no-cache-dir\n",
        "# ! pip install sacrebleu --no-cache-dir\n",
        "\n",
        "\n",
        "import evaluate\n",
        "metric = evaluate.load(\"sacrebleu\")"
      ],
      "metadata": {
        "id": "EnsLmm-XfYOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    # In case the model returns more than the prediction logits\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace 0s in the labels as we can't decode them\n",
        "    labels = np.where(labels != 0, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    return {\"bleu\": result[\"score\"]}"
      ],
      "metadata": {
        "id": "9YKGffYLfYQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install accelerate -U\n",
        "! pip install transformers -U"
      ],
      "metadata": {
        "id": "rPpeWRfAHTvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR']\n",
        "# !pip install cloud-tpu-client==0.10 torch==1.13.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.13-cp38-cp38-linux_x86_64.whl\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION\n",
        "import os\n",
        "os.environ['LD_LIBRARY_PATH']='/usr/local/lib'\n",
        "!echo $LD_LIBRARY_PATH\n",
        "\n",
        "!sudo ln -s /usr/local/lib/libmkl_intel_lp64.so /usr/local/lib/libmkl_intel_lp64.so.1\n",
        "!sudo ln -s /usr/local/lib/libmkl_intel_thread.so /usr/local/lib/libmkl_intel_thread.so.1\n",
        "!sudo ln -s /usr/local/lib/libmkl_core.so /usr/local/lib/libmkl_core.so.1\n",
        "\n",
        "!ldconfig\n",
        "!ldd /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so"
      ],
      "metadata": {
        "id": "yTOOTRHFGdL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/settings/tokens --> Token generation page for HuggingFace"
      ],
      "metadata": {
        "id": "s6u2GlEMHDoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "UXMFi9zPh92_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kmqIQLv5GWCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "import accelerate\n",
        "import transformers\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"multilingual_llm\",\n",
        "    evaluation_strategy=\"no\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=3,\n",
        "    predict_with_generate=True,\n",
        "    # fp16=True,\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "vRReIv4XfYS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "tcZPxlaxh6hN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(max_length=max_length)"
      ],
      "metadata": {
        "id": "S_13Co2ufYUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "qQ74JJ_qlnqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(tags=\"translation\", commit_message=\"Pretrainedt5 epoch3\")"
      ],
      "metadata": {
        "id": "_oEC6qzYgkH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation_hi_to_en\", model=\"multilingual_llm\")\n",
        "text = [\"आपका नाम क्या है\", \"आपका घर कहाँ है\"]\n",
        "translator(text)"
      ],
      "metadata": {
        "id": "PNxTO_NbiRKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3j4eJzUoiRMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O2OeuH3XiRPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eThbDNuQiRRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kWuiXGv_iRTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2FTXxb-ziRV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kdKkuh_uiRXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tQHUM_ktxrpE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}