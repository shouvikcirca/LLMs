{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shouvikcirca/LLMs/blob/openai/langchain_openai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! python --version\n",
        "! pip install --upgrade langchain\n",
        "! pip install python-dotenv\n",
        "! pip install --upgrade openai\n",
        "! pip install pypdf\n",
        "! pip install tiktoken\n",
        "! pip install chromadb\n",
        "# ! pip install cohere\n"
      ],
      "metadata": {
        "id": "w4yKsjPQ3rXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "metadata": {
        "id": "xazDLq0Q4HX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d56e28c-85fd-4651-8d45-83db75ff5b14"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! ls drive/MyDrive"
      ],
      "metadata": {
        "id": "HgV2GGJm4SAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "import sys\n",
        "import openai"
      ],
      "metadata": {
        "id": "eRrRZfelUY7I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = load_dotenv('drive/MyDrive/env')\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']\n"
      ],
      "metadata": {
        "id": "Ggulgf3PUZHj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader('drive/MyDrive/C-CARES_FRS_Grievance_Redressal.pdf')\n",
        "pages = loader.load()\n",
        "len(pages)"
      ],
      "metadata": {
        "id": "nwCspwg4UZQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cb8abc8-7eaa-4c42-eec9-dda081155bd9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# page = pages[3]\n",
        "# print(page.page_content[:1000])"
      ],
      "metadata": {
        "id": "1FpZXvvfUZVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# page.metadata"
      ],
      "metadata": {
        "id": "LWCulmW8UZY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter, TokenTextSplitter"
      ],
      "metadata": {
        "id": "hL6BgM5EtbPB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 50\n",
        "chunk_overlap = 10"
      ],
      "metadata": {
        "id": "SjhQF1nztbRw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# r_splitter = RecursiveCharacterTextSplitter(\n",
        "#     chunk_size=chunk_size,\n",
        "#     chunk_overlap=chunk_overlap\n",
        "# )\n",
        "# c_splitter = CharacterTextSplitter(\n",
        "#     chunk_size=chunk_size,\n",
        "#     chunk_overlap=chunk_overlap,\n",
        "#     length_function = len\n",
        "# )\n",
        "t_splitter = TokenTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        ")"
      ],
      "metadata": {
        "id": "9j-BMZR1tbUO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = t_splitter.split_documents(pages)\n",
        "len(docs)"
      ],
      "metadata": {
        "id": "TL48s389tbWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8de2f8-bf35-4f31-8d79-76fe97dd288f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "embedding = OpenAIEmbeddings(\n",
        "    api_key=openai.api_key\n",
        ")"
      ],
      "metadata": {
        "id": "ujNI7Rf3tbYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d6d4784-78f3-4c9d-b9ba-3646677c8240"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "55cSbqX2tbcK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# persist_directory = 'docs/chroma/'"
      ],
      "metadata": {
        "id": "QFP3Qr7Bsnp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma.from_documents(\n",
        "    documents=docs,\n",
        "    embedding=embedding,\n",
        "    # persist_directory=persist_directory\n",
        ")"
      ],
      "metadata": {
        "id": "-4iFjshtsnr2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectordb._collection.count())"
      ],
      "metadata": {
        "id": "ZPkzxv86wHOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20f3e0c-0aff-4ea5-ca09-0caea0531782"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the grievance redressal module designed for ?\""
      ],
      "metadata": {
        "id": "nTJQe3PQsnuX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similardocs = vectordb.similarity_search(question, k = 5)"
      ],
      "metadata": {
        "id": "SM9APo9CsnwT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectordb.persist() # So that we can use the vector database in the future"
      ],
      "metadata": {
        "id": "WsNyS_3Usn0J"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -qU langchain-openai"
      ],
      "metadata": {
        "id": "L4BaE7o27VEp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", api_key=openai.api_key)"
      ],
      "metadata": {
        "id": "gq5o--dcsn2x"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "S0Phx3Km7f3t"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Build prompt\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Elaborate as much as possible.\n",
        "{context}. Don not append anything that is not relevant ot the question. Answer in the following format\n",
        "\n",
        "Here is the question\n",
        "{question}\n",
        "\n",
        "Answer in the following format\n",
        "Answer: Answer\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "GK8HuT0d7kRN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI(api_key=openai.api_key)"
      ],
      "metadata": {
        "id": "XZAwCSNB8BpR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=vectordb.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")"
      ],
      "metadata": {
        "id": "8oHt4dXf7pa1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain({\"query\": \"How many functional requirements are there ?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YTq-hQ88LU1",
        "outputId": "63ccfe11-5504-4a22-b620-c9a3e531f285"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"result\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "2qRd1bDt8TMR",
        "outputId": "601dac37-b630-4abd-b163-c6471bf570a4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer: There are four functional requirements for the Grievance Redressal system: Grievance Category, Grievance Description, Supporting Documents, and File Upload.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}